This master thesis gave the FlowSight platform the ability to distinguish not only between browsing traffic and other types of traffic as it already did, but also to categorize the browsing traffic 
itself depending on the content of the web page. \\ 


The scope of this thesis in terms of requirements and time was somehow set by the client, but once the delivery is done we can try to go further and think about what could be done even better.\\
After applying all sorts of refining to the classification there are still some sites that are not being classified correctly. A clear example is the url \codi{youtube.com}. Whereas it is supposed to be
a social network or entertainment website, its content is generated by the users themselves and just a small percentage of the text in the page talks about what it really is.
This causes the website to be classified differently depending on the "social trends" of whenever the content was crawled. This issue is one of the most difficult to solve, and maybe the only way 
of solving it by now is using the meta information provided by the website itself.\\

The feature of language detection is already implemented but the platform is not taking advantage of all its potential. When a web page content is detected to be different than English it is automatically
categorized as \codi{Other} although its content could be related to the categories we are trying to classify. To avoid this situation and get an almost perfect classification one could generate a 
classification model for all known languages and use the language identification module to choose which model to apply for each of the web pages. Having this information we could get even more intelligence
out of the data by analyzing how foreigners behave in the network.\\

Using labeled data and supervised learning is suitable for situations where all the knowledge related to how the data is clustered is known in advance. It might seem logical to categorize web pages
depending on their subject, but all the information we will obtain will be delimited to the initial knowledge, that is, no new knowledge is extracted from the data. Users though, don't think about
categories when consuming web content, they simply consume using the algorithm of what their brains dictate.\\
Using unsupervised learning algorithms like \codi{k-means} and adding new variables like 
time, age, gender, etc, to discover new structures in the data might help us understand how our brain works, what users want and how and when they want it, providing a new level of knowledge that could
be applied in enhancing the users' everyday experience.

