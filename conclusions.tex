This master thesis gave the FlowSight platform the ability to distinguish not only between browsing traffic and other types of traffic as it already did, but also to categorize the browsing traffic 
itself depending on the content of the web page. \\ 


The scope of this thesis in terms of requirements and time was somehow set by the client, but once the delivery is done we can try to go further and think about what could be done even better.\\
After applying all sorts of refining to the classification there are still some sites that are not being classified correctly. A clear example is the url \codi{youtube.com}. Whereas it is supposed to be
a social network or entertainment website, its content is generated by the users themselves and just a small percentage of talks about what it really is.
This causes the website to be classified differently depending on the "social trends" of whenever the content was crawled.\\
The feature of language detection is already implemented but the platform is not taking advantage of all its potential. When a web page content is detected to be different than English it is automatically
categorized as \codi{Other} although its content could be related to the categories we are trying to classify. To avoid this situation and get an almost perfect classification one could generate a 
classification model for all known languages and use the language identification module to choose which model to apply for each of the web pages. Having this information we could get even more intelligence
out of the data by analyzing how foreigners behave in the network.\\
Using labeled data and supervised learning is suitable for situations where all the knowledge related to how the data is clustered is known in advance. It might seem logical to categorize web pages
depending on their subject, but all the information we will obtain will be delimited to the initial knowledge, that is, no new knowledge is extracted from the data. Users though, don't think about
categories when consuming web content, they simply consume using the algorithm of what their brains dictate.\\
Using unsupervised learning algorithms like \codi{k-means} and adding new variables like 
time, age, gender, etc. to discover new structures in the data might help us understand how our brain works, and if we understand how it works, one can focus on enhancing its every day experience.

