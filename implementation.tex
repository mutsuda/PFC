Although decision trees and Naive Bayes performed well during the rapidminer tests, they have some inherent issues to their specification. Decision trees are accurate, but their performance is 
not suitable for an almost real time high demanding environment. Naive Bayes is better at performance but it makes independence assumptions that could cause some classification problems.\\
There is an algorithm though that is both efficient (although it's not as fast as Naive Bayes) and doesn't make any assumption. It's called Maximum Entropy (or Logistic Regression).

\section{Maximum entropy concept}
Maximum entropy, also known as logistic regression focuses on minimizing commitment in its classifications. It is based on the principle of modeling all that is known satisfying a set of constraints
that must hold respecting uniformity, and assuming nothing about what is unknown.

One nice aspect of maximum entropy is that it does not suffer from any independence assumptions.\\
For example, consider a document containing the same number of occurrences of \codi{rainy} and \codi{social network}.\\
A Naive Bayes classifier will double count the occurrences of \codi{social network} 
- it will add in the weight for \codi{social} and the weight for \codi{network}. Since \codi{rainy} and
\codi{social network} occur equally, a single occurrence of \codi{social network} will contribute twice the weight as an occurrence of \codi{rainy}. This will cause Naive Bayes to prefer one class 
incorrectly.
Maximum entropy, on the other hand, will discount the $\lambda_i$ for each of these features such that their weight towards classification is appropriately reduced by half.
This is because the constraints work over expectations of the counts. \\
One implication for this freedom from independence assumptions is that bigrams and phrases can be easily added as features by maximum entropy, without worry that the features are overlapping.


%\begin{itemize}
%\item Compute $d_j, j=1,...,k+1$
%\item Initialize $\lambda_j^{(1)}$ to zero
%\item Repeat until converge
%\item For each j 
%  \begin{itemize}
%  \item Compute $E_{p^{(n)}} f_j = \sum\limits_{x \in \varepsilon} p^{(n)} (x)f_j(x)$
%    where $p^{(n)}(x) = \frac{e^{\sum\limits_{j=1}^{k+1}\lambda_j^{(n)}f_j(x)}}{Z}$ 
%  \item Update $\lambda_j^{(n+1)} = \lambda_j^{(n)} + \frac{1}{C}(log\frac{d_i}{E_{{p^{(n)}}}f_j})$
%  \end{itemize}
%\end{itemize}

  

\section{Feature selection}
In Chapter \ref{chap:research} we compared two feature selection algorithms related to text corpus. We observed how when using small amounts of data both algorithms performed similarly whereas once
large amounts of text were used counting the term frequency gave better accuracy results. The term frequency counting algorithm is also faster so it was the chosen algorithm for the final 
implementation in the platform.


\section{Configuration files}
\label{sec:config}
In order to run the categorization algorithm workflow inside the FlowSight platform some configuration files are needed. The first one \ref{fig:{config/maxent_builder.cfg}} is used to generate a model with the already existing and labeled
data crawled from the Yahoo! directory. The second one \ref{fig:{config/maxent_classifier.cfg}} performs the categorization itself using the previously generated model. This configuration files are
parsed once the application is running and they are detected as tasks that can be executed.


\inputcfg{config/maxent_builder.cfg}{MaxEnt model builder configuration file}

\clearpage
\inputcfg{config/maxent_classifier.cfg}{MaxEnt classifier configuration file}

\section{Performance evaluation}
%!Run the tests with m1r1, m2r1, m3r1, m4r1, m5,r1, mr2r2, m3r3, m4r4, m5r5, or etc...
\subsection{Overall performance}
Compared to other classification algorithms like Naive Bayes, the Maximum Entropy algorithm has a higher computational requirement. 
The platform where the MaxEnt classification algorithm is running is highly scalable and follows the map/reduce paradigm. Taking advantage of the paradigm, the MaxEnt algorithm
is able to perform notably faster.


\grafic{graphs/sclass2dmr.tex}{2D Performance graph}

Figure \ref{fig:{graphs/sclass2dmr.tex}} represents the performance (in categorized pages per second) of the same algorithm with different number of mappers and reducers, in two different machines: \codi{ultraman (Intel Core 2 Duo CPU 2.00GHz 4GB RAM)} 
is the machine where I'm writing most of this document, and \codi{rogue (Intel Core 2 Quad CPU Q9300 @ 2.5GHz 8GB RAM)} is a more powerful machine used for testing purposes. The \codi{x} axis represents the 
different mapper and reducer combinations I tested while the \codi{y} axis represents the number of categorized pages per second.
As we can see both machines perform similarly when using one to two mappers, but the most powerful machine outperforms the other one when using more than two mappers. We can also observe how \codi{ultraman}'s performance
quickly stalls for more than three mappers, while \codi{rogue} is able to hold a rising performance until six mappers are used.

Figure \ref{fig:{graphs/sclass3dmr.tex}} is a three dimensional representation of \codi{ultraman}'s performance. We can quickly observe a repeating pattern for each number of mappers.
\grafic{graphs/sclass3dmr.tex}{3D Performance graph}

\subsection{Detailed performance}
We saw how using the \codi{rogue} machine the performance of the classification reached its top when using 5 mappers, but the reason this happens seems to be unknown. 
Fortunately, the FlowSight platform offers the possibility of analyzing the performance of each of the mappers during each task. As we saw in Section \ref{sec:config} the execution of the classification
task depends on other subtasks like reading the directory, reading the content of each file that needs to be classified, and also performing some small operations after the classification is done and before
the result is written. Using the available FlowSight statistics we can locate the bottleneck that is causing the performance to stall even if more mappers are added. \\ 
In figure \ref{fig:{graphs/stats.tex}} we can see how when using more mappers almost all tasks perform better, including the classification task itself. Looking at the magnified section we can observe
that the task of reading the directory is the only one decreasing in performance, and so, causing the bottleneck. 

\grafic{graphs/stats.tex}{Performance for each task}

